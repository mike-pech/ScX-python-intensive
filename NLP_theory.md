# Виды анализа текста
## Графематический анализ (Сегментация)
Выделение в тексте предложений и словоформ, точнее токенов (т.к. текст может состоять не только из слов). Переход от символов (интерпретируемых человеком как отдельные слова) к словам (которые, как сказано компьютеру, являются отдельными токенами)
### Включает в себя:
* Различение знаков припинания, в роде тире ("—" или em-dash), дефиса (en-dash, как знак переноса) и истинного дефиса ("-")
* Сборка слов стоящих вразрядку: З а я в л е н и е  -> Заявление
* Нормализация форматов дат и прочих токенов: 11:00PM -> 23:00
* Восстановление правильного регистра (truecase): тюмень или ТЮМЕНЬ -> Тюмень. Может быть выполнена при помощи токенизации на предложения (предложения начинаются с высокого регистра), более глубокого анализа токенов (выявления их части речи и является ли она именем собственным) или нейронной сети (выявление закономерностей в Повышении регистра в словах и угадывание регистра)
* Свёртка сложносоставных предлогов и устойчивых неизменяемых оборотов ("ни у кого", "так сказать") — для этого хорошо подходит MWETokenizer из библиотеки nltk
* Обработка сокращений слов и словосочетаний ("I'm", "г. Тюмень", "д/з")
* Выделение полного имени (М.С. Печёркин)
Лексическое разнообразие текста после токенизации и чистки от ненужных символов (НЕ СТОП СЛОВ) определяется по формуле: количество уникальных слов / общее количество слов
## Морфологический анализ
### Морфология
Изучает внутреннюю структуру и внешнюю форму слов, включая части речи и их категории.
Переход от словоформ к их леммам (словарным формам лексем — _Лемматизация_ — кропотливое восстановление исходной формы слова) или основам (ядерным частям слова — _Стемминг_ — тупо обрубание не основных частей слова)
## Синтаксический анализ 
### Синтаксис
Изучает структуру предложений, правила сочетаемости и порядка следования слов в предложении, а также общие его свойства как единицы языка
<br>
Выявление синтаксических связей слов и грамматической структуры предложений. Иными словами, мы берём те токены, которые компьютер теперь видит как отдельные токены, и, по словарям, заставляем компьютер видеть связи межу ними. 
<br>
#### Синтаксический анализ делится на:
* Глубокий (полный) или deep parsing — используется для диалоговых систем и извлечения краткой выдержки из текста. Затрагивает смысловую часть текста и позволяет строить предположения о смысловых связях в разных по синтаксису, но схожих по смыслу предложениях
* Поверхностный или shallow parsing — используется для извлечения каких-либо слов из текста или для интелектуального анализа текста. Затрагивает только структуру и лексический и морфологический составы текста
<br>
<br>
__Предикат__ — слово подчиняющее себе другие слова и синтаксические конструкции предложения и определяющее их граматическую форму, а иногда и значение (). У каждого предиката есть вершина (сам предикат) и валентность (слоты, где в соответствии с условиями грамматических характеристик и семантического значения могут распологаться подчинённые предикату актанты) Предикатами в русском языке являются глаголы, глагольные формы, отглагольные (т.е. образованные непосредственно от глагола) существительные и прилагательные, а также предлоги.<br>
__Актант__ — слово или синтаксическая конструкция, заполняющая валентность предиката.
<br>
#### TF-IDF (Term Freuency — Inverse Document Frequency)
Это мера важности термина в тексте по тому, как часто он встречается в документах корпуса и в скольки документах из корпуса он встречается. TF-компонент считает сумму унитарных представлений состовляющих слов документа (считается как количество_упоминаний_термина_в_документе/общее_количество_терминов_в_документе). IDF-компонент снижает вес распространённых лексем и повышает вес редких лексем в векторном представлении (считается как логарифм(количество_документов_в_корпусе/количество_документов_с_термином_в_корпусе)).
## Семантический и прагматический анализ
Определяется смысл фраз и соответсвующая реакция (sentiment)<br>
Путём:<br>
* Словарей оценочной лексики — General Inquirer (Поз/Нег + Сил/Слаб + Удовольст/Боль/Моральные оценки), ANEW (9б. шкалы оценки Удовольствие/Неудовольствиеб Возбуждённость/Спокойствие, Котролирующий/Контролируемый), MPQA (Метки полярности Поз/Нейт/Нег и сила Слабое/Сильное), AFINN (для соц сетей, с матом и сленгом) для английского языка и PredictSentiRus (Вычисляет только оценочность, но не сам сентимент), РуСентиЛекс (литературный и сленговый русский с хотя бы одним оценочным компонентом)
* Косинусное расстояние (слова с похожими векторами скорее всего схожи по значению)
* TF-IDF
* Нейросети (RandomForest и т.д.)
<br>
__BagOfWords (или BoW)__ — отличается от One-Hot encoding`а тем, что считает множества слов, встречающихся в предложениях так, что слова могут иметь разное количество упоминаний. BoW1 = {"John":1,"likes":2,"to":1,"watch":1,"movies":2,"Mary":1,"too":1}; Тесно связана с теорией множеств.
<br>
## Чатботы
Чат-бот — это программа, имитирующая человеческое общение. Используется как для ведения неконструктивного диалога (тарантиновские диалоги со всякими чатами гхпт), так и для решения конкретных задач (чаще всего через конечные автоматы). Он надёжен, многозадачен, имеет concurrency (синхронность, не параллелелизм), легче в написании, уходе и передаче информации, чем кожанные мешки. Поэтому их всё больше и больше применяют в бизнесе, где проще простого оформить первую (или даже вторую, а может даже и третью) линюю поддержки через чат-бота. <br>
Чат-боты классифицируются по типу ввода текст, ключевые слова, кнопки (свобода общения убывает) и по назначению (Общее или под конкретную задачу), а также по домену (открытый или закрытый)

